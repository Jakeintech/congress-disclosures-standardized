import boto3
import json
import os
import logging
from typing import List, Set

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

S3_BUCKET = os.environ.get("S3_BUCKET_NAME", "congress-disclosures-standardized")

def get_bronze_ptrs(year: int) -> Set[str]:
    """Get set of Doc IDs for Type P filings in Bronze layer."""
    s3 = boto3.client("s3")
    bronze_ids = set()
    
    # Path: bronze/house/financial/year={year}/filing_type=P/pdfs/
    # Note: Ingestion might be putting them in year={year}/pdfs/{year}/... check both?
    # Based on previous context, they are in year={year}/pdfs/{year}/... but we need to filter by filing type.
    # The manifest is the best source of truth for "what is a PTR".
    
    # Let's use the manifest API if available, or list the index
    # Using index is safer: bronze/house/financial/year={year}/index/
    
    # Actually, let's look at the manifest generated by build_bronze_manifest.py
    # It's at website/api/v1/documents/manifest.json
    
    try:
        response = s3.get_object(Bucket=S3_BUCKET, Key="website/api/v1/documents/manifest.json")
        manifest_data = json.loads(response['Body'].read().decode('utf-8'))
        
        # Manifest structure: {"stats": {...}, "filings": [...]}
        filings = manifest_data.get('filings', [])
        
        for filing in filings:
            if filing.get('filing_type') == 'P' and filing.get('year') == year:
                # doc_id is string in manifest
                bronze_ids.add(str(filing.get('doc_id')))
                
        logger.info(f"Found {len(bronze_ids)} PTRs in Bronze manifest for {year}")
        return bronze_ids
        
    except Exception as e:
        logger.error(f"Failed to read manifest: {e}")
        return set()

def get_silver_ptrs(year: int) -> Set[str]:
    """Get set of Doc IDs that have structured data in Silver layer."""
    s3 = boto3.client("s3")
    silver_ids = set()
    
    # Correct path: silver/house/financial/structured_code/year={year}/filing_type=P/
    prefix = f"silver/house/financial/structured_code/year={year}/filing_type=P/"
    paginator = s3.get_paginator("list_objects_v2")
    
    for page in paginator.paginate(Bucket=S3_BUCKET, Prefix=prefix):
        for obj in page.get("Contents", []):
            # Key format: .../doc_id=DOCID.json
            key = obj["Key"]
            if key.endswith(".json"):
                # Extract DOCID from doc_id=DOCID.json
                filename = key.split("/")[-1]
                if filename.startswith("doc_id="):
                    doc_id = filename.replace("doc_id=", "").replace(".json", "")
                    silver_ids.add(doc_id)
                
    logger.info(f"Found {len(silver_ids)} PTRs with structured data in Silver for {year}")
    return silver_ids

def main():
    year = 2025
    bronze_ids = get_bronze_ptrs(year)
    silver_ids = get_silver_ptrs(year)
    
    missing_ids = bronze_ids - silver_ids
    
    logger.info(f"Total Bronze PTRs: {len(bronze_ids)}")
    logger.info(f"Total Silver Structured: {len(silver_ids)}")
    logger.info(f"Missing Structured Data: {len(missing_ids)}")
    
    if missing_ids:
        print("\nSample Missing Doc IDs (Top 20):")
        for doc_id in list(missing_ids)[:20]:
            print(doc_id)
            
        # Save full list to file
        with open("missing_ptr_ids.txt", "w") as f:
            for doc_id in missing_ids:
                f.write(f"{doc_id}\n")
        print("\nFull list saved to missing_ptr_ids.txt")

if __name__ == "__main__":
    main()
